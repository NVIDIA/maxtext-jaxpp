# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# NVIDIA CORPORATION and its licensors retain all intellectual property
# and proprietary rights in and to this software, related documentation
# and any modifications thereto.  Any use, reproduction, disclosure or
# distribution of this software and related documentation without an express
# license agreement from NVIDIA CORPORATION is strictly prohibited.

workflow:
  rules:
    - if: $CI_MERGE_REQUEST_IID
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_REF_PROTECTED == "true"

default:
  before_script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  interruptible: true

stages:
  - build
  - deploy
  - test

variables:
  GIT_SUBMODULE_STRATEGY: recursive
  GIT_SUBMODULE_FORCE_HTTPS: "true"
  JAX_VERSION: "0.4.29"
  CI_DEV_BRANCH: "jaxpp_main"
  TEST_IMAGE: "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
  LATEST_IMAGE: "$CI_REGISTRY_IMAGE:latest"
  DOCKERFILE: "jaxpp.Dockerfile"
  BASE_IMAGE: "gitlab-master.nvidia.com:5005/cml/jaxpp_dev/jaxpp:0231a2d4-base"

build_image:
  stage: build
  script:
    - docker build --force-rm=true
      -f ${DOCKERFILE}
      --build-arg BASE_IMAGE=$BASE_IMAGE
      -t ${TEST_IMAGE} $CI_PROJECT_DIR
    - docker push ${TEST_IMAGE}
  after_script:
    - docker rmi ${TEST_IMAGE}

tag_latest:
  stage: deploy
  interruptible: false
  script:
    - docker pull ${TEST_IMAGE}
    - docker tag ${TEST_IMAGE} ${LATEST_IMAGE}
    - docker push ${LATEST_IMAGE}
  after_script:
    - docker rmi ${LATEST_IMAGE}
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEV_BRANCH'

llama2-jax:
  stage: test
  script:
    - docker run --gpus=all --shm-size=10.24gb --ulimit memlock=-1 --ulimit stack=67108864
      -e RAY_ADDRESS=local --rm --workdir /workdir/maxtext ${TEST_IMAGE}
      "nvidia-smi && bash /workdir/maxtext/scripts/1gpu_jax.sh --max_target_length=8 --model=llama2-0_1b"

  after_script:
    - docker rmi $TEST_IMAGE


llama2-jaxpp:
  stage: test
  script:
    - docker run --gpus=all --shm-size=10.24gb --ulimit memlock=-1 --ulimit stack=67108864
      -e RAY_ADDRESS=local --rm --workdir /workdir/maxtext ${TEST_IMAGE}
      "nvidia-smi && bash /workdir/maxtext/scripts/multigpu_jaxpp.sh --dp=1 --pp=1 --mp=1 --batch_size_per_device=1 --max_target_length=8 --num_microbatches=1 --model=llama2-0_1b"

  after_script:
    - docker rmi $TEST_IMAGE


